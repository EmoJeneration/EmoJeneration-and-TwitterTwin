{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c745e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load BERTweet tokenizer and model\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in other necessary packages\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the desired dataset and ensure that age column is an int\n",
    "dataset = pd.read_csv('filepath')\n",
    "dataset['age'] = dataset['age'].astype(int)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78926c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode text data\n",
    "dataset['encoded_text'] = dataset['clean'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, padding=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Text Encoding and Padding: The text data was previously encoded and padded using BERTweet embeddings. \n",
    "This encoding and padding process converts the text into numerical representations, and the padding ensures \n",
    "that all input sequences have the same length.\n",
    "This transformation allows you to use the embeddings directly as features for your model.'''\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Convert the 'encoded_text' column to a list of tensors\n",
    "encoded_tensors = [torch.tensor(encoded) for encoded in dataset['encoded_text']]\n",
    "\n",
    "# Pad the embeddings to ensure they have the same length within each batch\n",
    "padded_embeddings = pad_sequence(encoded_tensors, batch_first=True)\n",
    "\n",
    "# Create a TensorDataset with padded embeddings and age labels\n",
    "dataset = TensorDataset(padded_embeddings, torch.tensor(dataset['age'].tolist()))\n",
    "\n",
    "# Create a DataLoader with the padded embeddings and age labels\n",
    "batch_size = 64  # Adjust as needed \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = padded_embeddings.numpy()  # Convert to NumPy array for XGBoost\n",
    "y = augmented_dataset['age'].values - 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44262a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the xgboost model, change parameters as needed\n",
    "model = xgb.XGBClassifier(objective='multi:softmax',  # For multi-class classification\n",
    "    num_class=len(np.unique(y_train)),\n",
    "    max_depth=6,                # Maximum depth of each tree\n",
    "    n_estimators=500,           # Number of boosting rounds\n",
    "    learning_rate=0.01,          # Learning rate (step size shrinkage)\n",
    "    subsample=0.8,              # Fraction of samples used for training each tree\n",
    "    colsample_bytree=0.8,       # Fraction of features used for training each tree\n",
    "    random_state=42 )            # Seed for reproducibility this is what we added for a tf-idf classifier on the same dataset, what should i use from here?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bdf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd63bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test set, measure accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall precision, recall, and F1 scores\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# define the positive class\n",
    "pos_label = 1\n",
    "\n",
    "# calculate precision, recall, and F1 score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, pos_label=pos_label, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "for class_label in range(5):\n",
    "    print(f\"Class {class_label}:\")\n",
    "    print(f\"Precision: {precision[class_label]}\")\n",
    "    print(f\"Recall: {recall[class_label]}\")\n",
    "    print(f\"F1 Score: {f1[class_label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Visualizing the scores for each class\n",
    "# List of class labels (e.g., Class 0, Class 1, Class 2)\n",
    "class_labels = [f'Class {i}' for i in range(len(precision))]\n",
    "\n",
    "# Values for precision, recall, and F1 score for each class\n",
    "precision_values = precision\n",
    "recall_values = recall\n",
    "f1_values = f1\n",
    "\n",
    "# Create subplots for precision, recall, and F1 score\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 12))\n",
    "\n",
    "# Plot precision\n",
    "axes[0].bar(class_labels, precision_values, color='b', alpha=0.7)\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision for Each Class')\n",
    "\n",
    "# Plot recall\n",
    "axes[1].bar(class_labels, recall_values, color='g', alpha=0.7)\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_title('Recall for Each Class')\n",
    "\n",
    "# Plot F1 score\n",
    "axes[2].bar(class_labels, f1_values, color='r', alpha=0.7)\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score for Each Class')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
