{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    "import pickle \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import gradio as gr\n",
    "\n",
    "# Load your trained model \n",
    "with open('/Users/olivia/DS/tfidf_cutdown_model.pkl', 'rb') as model_file:\n",
    "       model = pickle.load(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords from the tweets\n",
    "special_characters = ['~', ':', \"'\", '+', '[', '\\\\', '@', '^',\n",
    "                      '{', '%', '(', '-', '\"', '*', '|', ',', '&', '<', '`', '}', '.', '_', '=', ']', '>', ';', '#', '$', ')','!','?', '/', '‚Äô', '‚Äú', '‚Äù', \"‚Ä¶\"]\n",
    "\n",
    "def replace_special(myemolist, myspeciallist):\n",
    "    for i in myspeciallist:\n",
    "        for j in range(len(myemolist)):\n",
    "            myemolist[j] = myemolist[j].replace(i, \"\")\n",
    "    return myemolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False, max_features = 1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b259455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the fitted vectorizer from the saved file\n",
    "with open('/Users/olivia/DS/tfidf_vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "    tfidf = pickle.load(vectorizer_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized, separated the emojis\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "t = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a predict function that takes a string as an input, processes the string in the same way that we did before\n",
    "training our model. Returns the predicted age group of the user who wrote the string.\n",
    "'''\n",
    "def predict(text):\n",
    "    try:\n",
    "        # Preprocess the input text\n",
    "        text = str(text)\n",
    "        text = replace_special([text], special_characters)[0]\n",
    "        text_df = pd.DataFrame({'text': [text]})\n",
    "        text_df['text'] = text_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "        text_df['tokenized'] = text_df.apply(lambda x: t.tokenize(x['text']), axis=1)\n",
    "        tokenized_tweet = list(text_df['tokenized'])\n",
    "\n",
    "        # Compute the TF-IDF representation of the preprocessed text\n",
    "        tf_tweets = tfidf.transform(tokenized_tweet)\n",
    "        tfidf_array = tf_tweets.toarray()\n",
    "        prediction = model.predict(tfidf_array)\n",
    "        if prediction[0] == 0:\n",
    "            return('18-25')\n",
    "        if prediction[0] == 1:\n",
    "            return('26-40')\n",
    "        if prediction[0] == 2:\n",
    "            return('41-55')\n",
    "        if prediction[0] == 3:\n",
    "            return('56-70')\n",
    "        if prediction[0] == 4:\n",
    "            return('71+')\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions raised by the function calls\n",
    "        error_message = f\"An error occurred during prediction: {str(e)}\"\n",
    "        return error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1debefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gradio interface\n",
    "output_text = gr.Textbox(label=\"Predicted age range: \")\n",
    "title = 'Welcome to EmoJeneration! üë∂üèªüßëüèª‚Äçü¶∞üë©üèªüßîüèº‚Äç‚ôÇÔ∏èüëµüèΩ'\n",
    "app_interface = gr.Interface(fn=predict, inputs= gr.Textbox(label = 'Enter some text:'), outputs=output_text, title = title)\n",
    "\n",
    "# Launch the interface\n",
    "app_interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c00d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
